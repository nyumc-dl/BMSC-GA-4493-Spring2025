{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886fe4fc-332a-4ffe-ac2b-e6df0d5ab202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdown --fuzzy https://drive.google.com/drive/folders/1VGye74GnNXbUMKx6QYYectZrY7G2pQ_J\n",
    "#git clone https://github.com/ml4bio/RNA-FM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e37a2-8c1f-4a33-9977-a4a4f9cf9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ptflops pytorch-ignite, yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe48f5c-0def-4f35-99f1-f557d12d4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/gpfs/home/nk4167/RNA-FM_pretrained.pth'\n",
    "yml_path ='/gpfs/home/nk4167/RNA-FM/redevelop/pretrained/ss_prediction.yml'\n",
    "rna_fm_folder='/gpfs/home/nk4167/RNA-FM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7455c8fd-c309-4f7a-9538-1c8bd439397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs='''>3ktw_C\n",
    "AGAUAGUCGUGGGUUCCCUUUCUGGAGGGAGAGGGAAUUCCACGUUGACCGGGGGAACCGGCCAGGCCCGGAAGGGAGCAACCGUGCCCGGCUAUC\n",
    ">2der_D\n",
    "CCCCUUCGUCUAGAGGCCCAGGACACCGCCCUUUCACGGCGGUAACAGGGGUUCGAAUCCCCUAGGGGACGG\n",
    ">1p6v_B\n",
    "GAUUCGACGGGGACUUCGGUCCUCGGACGCGGGUUCGAUUCCCGC'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16cb30dc-81e4-4498-9a3d-7f87508d1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_path = '/gpfs/home/nk4167/NK_test.fasta'\n",
    "import os\n",
    "try:\n",
    "    os.remove(fasta_path)\n",
    "except:\n",
    "    print(\"File does not exist anyway\")\n",
    "with open(fasta_path,'w+') as f:\n",
    "    f.write(fasta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe8e64e-c22e-4bd1-a7d9-ad4b287b09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a4275a-e022-4d6a-b491-baeeebbb52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/gpfs/home/nk4167/RNA-FM/redevelop/data')\n",
    "\n",
    "sys.path.append('/gpfs/home/nk4167/RNA-FM/redevelop/model')\n",
    "\n",
    "sys.path.append('/gpfs/home/nk4167/RNA-FM/redevelop/engine')\n",
    "\n",
    "sys.path.append('/gpfs/home/nk4167/RNA-FM/redevelop/config')\n",
    "\n",
    "sys.path.append('/gpfs/home/nk4167/RNA-FM/redevelop/utils')\n",
    "sys.path.append('/gpfs/home/nk4167/RNA-FM/redevelop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed2d8a9-cf28-4edc-bda9-9b3b29f830eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(rna_fm_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133949b1-0311-4e19-a4de-19d52febf7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done parsing\n",
      "2025-04-03 08:23:41,260 prediction INFO: Using 1 GPUS, GPU ID: 0\n",
      "2025-04-03 08:23:41,262 prediction INFO: Loaded configuration file /gpfs/home/nk4167/RNA-FM/redevelop/pretrained/ss_prediction.yml\n",
      "2025-04-03 08:23:41,262 prediction INFO: Model File:/gpfs/home/nk4167/RNA-FM_pretrained.pth\n",
      "2025-04-03 08:23:41,265 prediction INFO: Batch Size:1\n",
      "2025-04-03 08:23:41,267 prediction INFO: Threshold:0.33993712\n",
      "2025-04-03 08:23:41,269 prediction INFO: Prediction Dataset: /gpfs/home/nk4167/NK_test.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://proj.cse.cuhk.edu.hk/rnafm/api/download?filename=RNA-FM_pretrained.pth\" to /gpfs/home/nk4167/.cache/torch/hub/checkpoints/RNA-FM_pretrained.pth\n",
      "  2%|██▉                                                                                                                                                                   | 19.8M/1.11G [00:12<09:55, 1.97MB/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Jiayang Chen\n",
    "@contact: yjcmydkzgj@gmail.com\n",
    "\n",
    "The required parameters include model_path, data_path, save_path, save_type\n",
    "\n",
    "Given the input sequences, output and save specific predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from os import mkdir\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from data import make_data_loader\n",
    "\n",
    "from model import build_model\n",
    "from engine.predictor import do_prediction\n",
    "\n",
    "from config import cfg\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "\n",
    "def seed_torch(seed=2018):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def predict(cfg, save_embeddings=False, save_embeddings_format=\"raw\", save_frequency=1, save_file_prefix=\"\",\n",
    "            threshold=0.5, allow_nc=True, allow_vis=True):\n",
    "    # build model and load parameter\n",
    "    model = build_model(cfg)\n",
    "    if cfg.EVAL.WEIGHT_PATH != \"none\":\n",
    "        model.load_param(\"overall\", cfg.EVAL.WEIGHT_PATH)\n",
    "\n",
    "    # prepare dataset\n",
    "    input_data_loader, _, _ = make_data_loader(cfg, model.backbone_alphabet, is_train=False)\n",
    "\n",
    "    # build and launch engine for evaluation\n",
    "    Eval_Record = do_prediction(cfg,\n",
    "                               model,\n",
    "                               input_data_loader,\n",
    "                               save_embeddings=save_embeddings,\n",
    "                               save_embeddings_format=save_embeddings_format,\n",
    "                               save_results=True,\n",
    "                               save_frequency=save_frequency,\n",
    "                               save_file_prefix=save_file_prefix,\n",
    "                               threshold=threshold,\n",
    "                               allow_noncanonical_pairs=allow_nc,\n",
    "                               allow_visualization=allow_vis\n",
    "                               )\n",
    "\n",
    "    # logging with tensorboard summaryWriter\n",
    "    #model_epoch = cfg.EVAL.WEIGHT_PATH.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    #model_iteration = len(input_data_loader) * int(model_epoch) if model_epoch.isdigit() == True else 0\n",
    "\n",
    "    #writer_test = SummaryWriter(cfg.SOLVER.OUTPUT_DIR + \"/summary/predict\")\n",
    "    #record_dict_into_tensorboard(writer_test, Eval_Record, model_iteration)\n",
    "    #writer_test.close()\n",
    "\n",
    "    # record in xlsx\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([value], columns=col_names)\n",
    "    xls_filename = os.path.join(cfg.SOLVER.OUTPUT_DIR, \"{}.xlsx\".format(csv_name))\n",
    "    if os.path.exists(xls_filename) != True:\n",
    "        with pd.ExcelWriter(xls_filename, engine=\"openpyxl\", mode='w') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        with pd.ExcelWriter(xls_filename, engine=\"openpyxl\", mode='a') as writer:\n",
    "            wb = writer.book\n",
    "            if sheet_name in wb.sheetnames:\n",
    "                old_df = pd.read_excel(xls_filename, sheet_name=sheet_name, index_col=0)\n",
    "                # remove old sheet, otherwise generate new sheets with suffix \"1\", \"2\",...\n",
    "                wb.remove(wb[sheet_name])\n",
    "                df = pd.concat([old_df, df], axis=0, ignore_index=True)\n",
    "                df.to_excel(writer, sheet_name=sheet_name)\n",
    "            else:\n",
    "                df.to_excel(writer, sheet_name=sheet_name)\n",
    "    #\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Classification Baseline Inference\")\n",
    "    parser.add_argument(\n",
    "        \"--config_file\", default=yml_path, help=\"path to config file\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\", default='/gpfs/home/nk4167/NK_test.fasta', help=\"path to data file or folder\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_dir\", default=None, help=\"path to savings\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_file\", default=model_path, help=\"file path to model\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_frequency\", default=1, help=\"file path to model\", type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_embeddings\", action='store_true'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_embeddings_format\", default=\"raw\", choices=[\"raw\", \"bos\", \"mean\"]\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_file_prefix\", default=\"\", type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--threshold\", default=-1, type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--forbid_nc\", action='store_true'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--allow_vis\", action='store_true'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", default=\"gpu\", choices=[\"cpu\", \"gpu\"]\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gpu_id\", default=0, type=int,\n",
    "    )\n",
    "\n",
    "\n",
    "    parser.add_argument(\"opts\", help=\"Modify config options using the command-line\", default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "\n",
    "    num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "\n",
    "    if args.config_file != \"\":\n",
    "        cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    print('Done parsing')\n",
    "    # custom defined symbols parsing\n",
    "    # (1). eval batch size\n",
    "    if cfg.EVAL.DATALOADER.BATCH_SIZE < 0:\n",
    "        cfg.EVAL.DATALOADER.BATCH_SIZE = -1 * cfg.EVAL.DATALOADER.BATCH_SIZE * cfg.DATA.DATALOADER.BATCH_SIZE\n",
    "\n",
    "    # (2). parser config name as work space\n",
    "    if args.config_file != \"\":\n",
    "        config_info = args.config_file.strip(\".yml\").split(\"/\")\n",
    "        config_parse_dir = \"\"\n",
    "        for c_i in config_info:\n",
    "            if c_i == \"CONFIGs\":\n",
    "                config_parse_dir += \"/\"\n",
    "            elif config_parse_dir != \"\":\n",
    "                config_parse_dir = config_parse_dir + c_i + \"/\"\n",
    "            else:\n",
    "                continue\n",
    "        cfg.SOLVER.OUTPUT_DIR = cfg.SOLVER.OUTPUT_DIR.replace(\"${CONFIG_NAME}\", config_parse_dir.strip(\"/\"))\n",
    "        weight_state = \"randinit\" if cfg.MODEL.BACKBONE_RANDOM_INITIALIZATION == 1 else \"pretrain\"\n",
    "        cfg.SOLVER.OUTPUT_DIR = cfg.SOLVER.OUTPUT_DIR.replace(\"${WEIGHT_STATE}\", weight_state)\n",
    "        stem_freeze = \"featbase\" if cfg.MODEL.BACKBONE_FROZEN == 1 else \"finetune\"\n",
    "        cfg.SOLVER.OUTPUT_DIR = cfg.SOLVER.OUTPUT_DIR.replace(\"${STEM_FREEZE}\", stem_freeze)\n",
    "\n",
    "    # (3). eval weight path\n",
    "    cfg.EVAL.WEIGHT_PATH = cfg.EVAL.WEIGHT_PATH.replace(\"${OUTPUT_DIR}\", cfg.SOLVER.OUTPUT_DIR)\n",
    "\n",
    "    # predict specific setting\n",
    "    cfg.DATA.DATASETS.NAMES = \"custom_seq_L:[1, 1022]_D:[-1,-1]\"\n",
    "    if args.data_path is not None:\n",
    "        cfg.DATA.DATASETS.ROOT_DIR = args.data_path\n",
    "    else:\n",
    "        raise Exception(\"Need Specify Data Path (file or folder)\")\n",
    "    if args.save_dir is not None:\n",
    "        cfg.SOLVER.OUTPUT_DIR = args.save_dir\n",
    "    else:\n",
    "        #raise Exception(\"Need Specify Save Dir\")\n",
    "        pass\n",
    "    if args.model_file is not None:\n",
    "        cfg.EVAL.WEIGHT_PATH = args.model_file\n",
    "\n",
    "    if args.threshold != -1:\n",
    "        threshold = args.threshold\n",
    "        cfg.MODEL.THRESHOLD = threshold\n",
    "    else:\n",
    "        threshold = cfg.MODEL.THRESHOLD\n",
    "\n",
    "    if args.device == \"cpu\":\n",
    "        cfg.MODEL.DEVICE = \"cpu\"\n",
    "    else:\n",
    "        cfg.MODEL.DEVICE = \"cuda\"\n",
    "        cfg.MODEL.DEVICE_ID = (args.gpu_id,)\n",
    "\n",
    "    cfg.freeze()\n",
    "\n",
    "    output_dir = cfg.SOLVER.OUTPUT_DIR\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    logger = setup_logger(\"prediction\", output_dir, \"prediction\", 0)\n",
    "    if args.device == \"gpu\":\n",
    "        logger.info(\"Using {} GPUS, GPU ID: {}\".format(num_gpus, args.gpu_id))\n",
    "    else:\n",
    "        logger.info(\"Using CPU\")\n",
    "    #logger.info(args)\n",
    "\n",
    "    if args.config_file != \"\":\n",
    "        logger.info(\"Loaded configuration file {}\".format(args.config_file))\n",
    "        with open(args.config_file, 'r') as cf:\n",
    "            config_str = \"\\n\" + cf.read()\n",
    "            #logger.info(config_str)\n",
    "    #logger.info(\"Running with config:\\n{}\".format(cfg))\n",
    "\n",
    "    logger.info(\"Model File:{}\".format(cfg.EVAL.WEIGHT_PATH))\n",
    "    logger.info(\"Batch Size:{}\".format(cfg.EVAL.DATALOADER.BATCH_SIZE))\n",
    "    logger.info(\"Threshold:{}\".format(threshold))\n",
    "\n",
    "    if cfg.MODEL.DEVICE == \"cuda\":\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = \",\".join(\"%s\"%i for i in cfg.MODEL.DEVICE_ID)   # int tuple -> str # cfg.MODEL.DEVICE_ID\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    logger.info(\"Prediction Dataset: {}\".format(cfg.DATA.DATASETS.ROOT_DIR))\n",
    "    allow_nc = not args.forbid_nc\n",
    "    predict(cfg, args.save_embeddings, args.save_embeddings_format, args.save_frequency, args.save_file_prefix,\n",
    "            threshold, allow_nc, args.allow_vis)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seed_torch(2018)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff0987-1f18-47d8-9ab1-503d345a8f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
