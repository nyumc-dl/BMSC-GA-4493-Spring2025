{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf19a2a-4229-41a5-b8e7-961e357c881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad86cd94-dcdb-4f10-a73b-bfc388f7b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b130211-6b48-4ea9-9f53-8468c40f624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Labels: torch.Size([64]) tensor([3, 2, 3, 0, 3, 3, 3, 3, 1, 2, 0, 1, 2, 1, 1, 1, 1, 3, 3, 1, 2, 3, 2, 0,\n",
      "        1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0, 0, 1, 0, 2, 2, 2, 0, 3, 1, 0, 2, 0,\n",
      "        2, 0, 2, 1, 0, 0, 1, 2, 1, 1, 3, 0, 1, 3, 1, 0])\n",
      "Batch Texts: torch.Size([64, 58]) tensor([[ 9124,  4917,  2019,  ...,     0,     0,     0],\n",
      "        [   97,    49,  1103,  ...,     0,     0,     0],\n",
      "        [ 3922,  8483,  1451,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1827,  8856,    30,  ...,     0,     0,     0],\n",
      "        [ 3123,  7214, 10428,  ...,     0,     0,     0],\n",
      "        [11172, 15041,   200,  ...,     0,     0,     0]])\n",
      "Vocab Size: 10845\n",
      "Number of Classes: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AG_NEWS_Dataset(Dataset):\n",
    "    def __init__(self, data, vocab, transform=None):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, text = self.data[idx]\n",
    "        if self.transform:\n",
    "            text = self.transform(text)\n",
    "        numerical_text = [self.vocab.get(word, self.vocab['<unk>']) for word in text] #Corrected line\n",
    "        return torch.tensor(label - 1, dtype=torch.int64), torch.tensor(numerical_text, dtype=torch.int64)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text.split()\n",
    "\n",
    "def build_vocab(data, min_freq=30):\n",
    "    counter = Counter()\n",
    "    for _, text in data:\n",
    "        counter.update(clean_text(text))\n",
    "    vocab = {word: idx + 2 for idx, (word, count) in enumerate(counter.items()) if count >= min_freq}\n",
    "    vocab['<pad>'] = 0\n",
    "    vocab['<unk>'] = 1\n",
    "    return vocab\n",
    "\n",
    "def download_and_extract(url, extract_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    file = tarfile.open(fileobj=io.BytesIO(response.content), mode='r:gz')\n",
    "    file.extractall(path=extract_path)\n",
    "\n",
    "def load_ag_news(root='.'):\n",
    "\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "\n",
    "\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    with open(os.path.join(root, 'train.csv'), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, title, description = line.strip().split('\",\"', 2)\n",
    "            label = int(label.replace('\"', ''))\n",
    "            title = title.replace('\"', '')\n",
    "            description = description.replace('\"', '')\n",
    "            train_data.append((label, title + \" \" + description))\n",
    "\n",
    "    with open(os.path.join('test.csv'), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, title, description = line.strip().split('\",\"', 2)\n",
    "            label = int(label.replace('\"', ''))\n",
    "            title = title.replace('\"', '')\n",
    "            description = description.replace('\"', '')\n",
    "            test_data.append((label, title + \" \" + description))\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def collate_batch(batch, pad_idx=0):\n",
    "    labels, texts = zip(*batch)\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=pad_idx)\n",
    "    labels = torch.stack(labels)\n",
    "    return labels, padded_texts\n",
    "\n",
    "def get_dataloaders(batch_size=64, min_freq=30, root='.'):\n",
    "    train_data, test_data = load_ag_news(root)\n",
    "    vocab = build_vocab(train_data, min_freq)\n",
    "\n",
    "    train_dataset = AG_NEWS_Dataset(train_data, vocab, transform=clean_text)\n",
    "    test_dataset = AG_NEWS_Dataset(test_data, vocab, transform=clean_text)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda batch: collate_batch(batch, pad_idx=vocab['<pad>']))\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda batch: collate_batch(batch, pad_idx=vocab['<pad>']))\n",
    "\n",
    "    return train_dataloader, test_dataloader, vocab, 4\n",
    "\n",
    "\n",
    "train_loader, test_loader, vocabulary, num_classes = get_dataloaders()\n",
    "\n",
    "for labels, texts in train_loader:\n",
    "    print(\"Batch Labels:\", labels.shape, labels)\n",
    "    print(\"Batch Texts:\", texts.shape, texts)\n",
    "    print(\"Vocab Size:\", len(vocabulary))\n",
    "    print(\"Number of Classes:\", num_classes)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbaa7fcd-5860-4f56-a36e-369bf581b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(enumerate(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4edfe81e-872e-4241-b9ac-ee0de04c0b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " (tensor([0, 2, 0, 0, 0, 3, 0, 1, 2, 3, 0, 2, 3, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 3,\n",
       "          2, 3, 0, 0, 0, 0, 2, 2, 3, 1, 2, 3, 2, 2, 1, 0, 1, 0, 3, 2, 0, 1, 2, 1,\n",
       "          2, 1, 1, 3, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 3]),\n",
       "  tensor([[ 3223,   436,   175,  ...,     0,     0,     0],\n",
       "          [ 3316,  7447, 10867,  ...,     0,     0,     0],\n",
       "          [ 2099,    14,  3733,  ...,     0,     0,     0],\n",
       "          ...,\n",
       "          [26326,  3454,   700,  ...,     0,     0,     0],\n",
       "          [24342,   168,     1,  ...,     0,     0,     0],\n",
       "          [ 4230,  9979,     1,  ...,     0,     0,     0]])))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "731e5962-fc77-403d-8aa2-14a472966ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 2, 0, 0, 0, 3, 0, 1, 2, 3, 0, 2, 3, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 3,\n",
       "         2, 3, 0, 0, 0, 0, 2, 2, 3, 1, 2, 3, 2, 2, 1, 0, 1, 0, 3, 2, 0, 1, 2, 1,\n",
       "         2, 1, 1, 3, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 3]),\n",
       " tensor([[ 3223,   436,   175,  ...,     0,     0,     0],\n",
       "         [ 3316,  7447, 10867,  ...,     0,     0,     0],\n",
       "         [ 2099,    14,  3733,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [26326,  3454,   700,  ...,     0,     0,     0],\n",
       "         [24342,   168,     1,  ...,     0,     0,     0],\n",
       "         [ 4230,  9979,     1,  ...,     0,     0,     0]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d9503a-241e-40bb-ba00-858bc3842ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpers \n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    batch_counter = 0\n",
    "    for labels, texts in iterator:\n",
    "        batch_counter = batch_counter + 1\n",
    "        if batch_counter % 1000 == 0:\n",
    "            print(batch_counter)\n",
    "        labels = labels.to(device)\n",
    "        texts = texts.to(device)\n",
    "        texts[texts >= VOCAB_SIZE] = UNK_IDX\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions, labels)\n",
    "        acc = calculate_accuracy(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for labels, texts in iterator:\n",
    "            labels = labels.to(device)\n",
    "            texts = texts.to(device)\n",
    "            texts[texts >= VOCAB_SIZE] = UNK_IDX\n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = calculate_accuracy(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    _, predicted_classes = torch.max(predictions, 1)\n",
    "    correct_predictions = (predicted_classes == labels).sum().float()\n",
    "    accuracy = correct_predictions / labels.size(0)  # Corrected line\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb83f25d-7317-41ae-a35c-a668e2743781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a Vanilla RNN\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self,vocab_size, embed_size, hidden_size, output_size,pad_idx):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size,padding_idx=pad_idx)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_ih = nn.Parameter(torch.Tensor(embed_size, hidden_size)) #Weights Input to hidden\n",
    "        self.W_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size)) #Weights Hidden to hidden\n",
    "        self.b_ih = nn.Parameter(torch.Tensor(hidden_size)) #Bias input to Hidden\n",
    "        self.b_hh = nn.Parameter(torch.Tensor(hidden_size)) #Bias hidden to hidden\n",
    "        \n",
    "        # Define a simple linear layer for the output.\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / (self.hidden_size ** 0.5)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def forward(self, x, hidden=None):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (batch_size, seq_len) (token indices)\n",
    "        hidden: Tensor of shape (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()  # Expect only 2D input (batch, seq_len)\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(batch_size, self.hidden_size, device=x.device, requires_grad=True)\n",
    "\n",
    "        # Embed the token indices into a 3D tensor (batch_size, seq_len, embed_size)**\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Process sequence one timestep at a time\n",
    "        hidden_states = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]  # Shape: (batch_size, embed_size)\n",
    "            hidden = torch.tanh(x_t @ self.W_ih + self.b_ih + hidden @ self.W_hh + self.b_hh)\n",
    "            hidden_states.append(hidden)\n",
    "        #Optional, but stabilizes training.\n",
    "        hidden = torch.stack(hidden_states, dim=1).mean(dim=1)  # Average across time steps\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45903d3-55d0-48f9-a15e-d64fc01ebc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 64\n",
    "    MIN_FREQ = 5\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_DIM = 256\n",
    "    OUTPUT_DIM = 4\n",
    "    NUM_LAYERS = 2\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    train_dl, test_dl, vocabulary, num_classes = get_dataloaders(batch_size=BATCH_SIZE, min_freq=MIN_FREQ)\n",
    "    VOCAB_SIZE = len(vocabulary)\n",
    "    PAD_IDX = vocabulary['<pad>']\n",
    "    UNK_IDX = vocabulary['<unk>']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = VanillaRNN(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, PAD_IDX).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device)\n",
    "        valid_loss, valid_acc = evaluate(model, test_dl, criterion, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.4f}, Val. Acc: {valid_acc*100:.2f}%')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfe48808-b861-4fe6-a193-2eb1c23e940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiLayerRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers=2, dropout=0.5, pad_idx=0):\n",
    "        super(MultiLayerRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # **Embedding layer for tokenized text**\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "\n",
    "        # **RNN Layers**\n",
    "        self.rnn_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_dim = embed_size if i == 0 else hidden_size  # First layer uses embedding, others use hidden_size\n",
    "            self.rnn_layers.append(nn.Linear(input_dim + hidden_size, hidden_size))  # Vanilla RNN logic\n",
    "\n",
    "        # **Layer normalization**\n",
    "        self.layer_norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n",
    "\n",
    "        # **Dropout**\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # **Final classification layer**\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Initializes weights uniformly.\"\"\"\n",
    "        stdv = 1.0 / (self.hidden_size ** 0.5)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (batch_size, seq_len) (tokenized text input)\n",
    "        hidden: Tensor of shape (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        x = self.embedding(x)  # Convert token indices to embeddings → (batch_size, seq_len, embed_size)\n",
    "\n",
    "        # Initialize hidden states if not provided\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        hidden_states = []  # Store hidden states over time\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]  # Extract timestep (batch_size, embed_size)\n",
    "            new_hidden = []\n",
    "\n",
    "            for i, rnn_layer in enumerate(self.rnn_layers):\n",
    "                hidden_prev = hidden[i]  # Previous hidden state for this layer\n",
    "                combined = torch.cat((x_t, hidden_prev), dim=-1)  # Merge input and previous hidden\n",
    "                hidden_new = torch.tanh(rnn_layer(combined))  # Apply transformation\n",
    "\n",
    "                # Apply layer normalization & dropout\n",
    "                hidden_new = self.layer_norms[i](hidden_new)\n",
    "                hidden_new = self.dropout(hidden_new)\n",
    "\n",
    "                new_hidden.append(hidden_new)  # Save new hidden state\n",
    "                x_t = hidden_new  # Pass to next layer\n",
    "\n",
    "            hidden = torch.stack(new_hidden, dim=0)  # Convert list to tensor (num_layers, batch_size, hidden_size)\n",
    "            hidden_states.append(hidden.unsqueeze(1))  # Add time step dimension\n",
    "        #Optional, but stabilized.\n",
    "        hidden_states = torch.cat(hidden_states, dim=1)  # Stack across time dimension (batch_size, seq_len, num_layers, hidden_size)\n",
    "        final_hidden = hidden_states[-1, :,:, :]  # All time step, last layer\n",
    "        hidden_avg = final_hidden.mean(dim=0)  # Average across time steps\n",
    "        out = self.fc(hidden_avg)\n",
    "        return out  # Return last hidden state for potential reuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d23704b-185d-425a-8652-d26ec618e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Epoch: 01, Train Loss: 0.8084, Train Acc: 67.46%, Val. Loss: 0.6266, Val. Acc: 76.16%\n",
      "1000\n",
      "Epoch: 02, Train Loss: 0.5462, Train Acc: 81.16%, Val. Loss: 0.4485, Val. Acc: 85.29%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 21\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m evaluate(model, test_dl, criterion, device)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Val. Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val. Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, labels)\n\u001b[1;32m     17\u001b[0m acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(predictions, labels)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 64\n",
    "    MIN_FREQ = 5\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_DIM = 256\n",
    "    OUTPUT_DIM = 4\n",
    "    NUM_LAYERS = 2\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    train_dl, test_dl, vocabulary, num_classes = get_dataloaders(batch_size=BATCH_SIZE, min_freq=MIN_FREQ)\n",
    "    VOCAB_SIZE = len(vocabulary)\n",
    "    PAD_IDX = vocabulary['<pad>']\n",
    "    UNK_IDX = vocabulary['<unk>']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = MultiLayerRNN(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, 2, 0.5,PAD_IDX).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device)\n",
    "        valid_loss, valid_acc = evaluate(model, test_dl, criterion, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.4f}, Val. Acc: {valid_acc*100:.2f}%')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a4e67a5-70a7-4576-b7ab-16cd2117d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easier way\n",
    "class TorchVanillaRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers, dropout,padding_idx):\n",
    "        super(TorchVanillaRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size,padding_idx=padding_idx)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers=num_layers, \n",
    "                          batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        output_avg = output.mean(dim=1)\n",
    "        return self.fc(output_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c809b08-2703-45db-b64a-8f1f7a5217a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Epoch: 01, Train Loss: 0.5309, Train Acc: 81.24%, Val. Loss: 0.3885, Val. Acc: 87.43%\n",
      "1000\n",
      "Epoch: 02, Train Loss: 0.3228, Train Acc: 89.56%, Val. Loss: 0.3347, Val. Acc: 89.15%\n",
      "1000\n",
      "Epoch: 03, Train Loss: 0.2763, Train Acc: 91.10%, Val. Loss: 0.3281, Val. Acc: 89.40%\n",
      "1000\n",
      "Epoch: 04, Train Loss: 0.2555, Train Acc: 91.64%, Val. Loss: 0.3139, Val. Acc: 89.96%\n",
      "1000\n",
      "Epoch: 05, Train Loss: 0.2218, Train Acc: 92.78%, Val. Loss: 0.3201, Val. Acc: 89.96%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 21\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m evaluate(model, test_dl, criterion, device)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Val. Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val. Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, labels)\n\u001b[1;32m     17\u001b[0m acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(predictions, labels)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 64\n",
    "    MIN_FREQ = 5\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_DIM = 256\n",
    "    OUTPUT_DIM = 4\n",
    "    NUM_LAYERS = 2\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    train_dl, test_dl, vocabulary, num_classes = get_dataloaders(batch_size=BATCH_SIZE, min_freq=MIN_FREQ)\n",
    "    VOCAB_SIZE = len(vocabulary)\n",
    "    PAD_IDX = vocabulary['<pad>']\n",
    "    UNK_IDX = vocabulary['<unk>']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TorchVanillaRNN(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, 2, 0.5,PAD_IDX).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device)\n",
    "        valid_loss, valid_acc = evaluate(model, test_dl, criterion, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.4f}, Val. Acc: {valid_acc*100:.2f}%')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f5f8c6d-2f69-4376-87e2-7408adb3bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pure Pytorch implementation of the GRU model for intuition\n",
    "class GRULayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Implements a single-layer GRU with custom initialization.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_size (int): Number of hidden units.\n",
    "        \"\"\"\n",
    "        super(GRULayer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Update\n",
    "        self.W_xz = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hz = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_z = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Reset\n",
    "        self.W_xr = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hr = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_r = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Hidden\n",
    "        self.W_xh = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Uses Xavier & Orthogonal initialization for stability.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.W_xz)\n",
    "        nn.init.xavier_uniform_(self.W_xr)\n",
    "        nn.init.xavier_uniform_(self.W_xh)\n",
    "        \n",
    "        nn.init.orthogonal_(self.W_hz)\n",
    "        nn.init.orthogonal_(self.W_hr)\n",
    "        nn.init.orthogonal_(self.W_hh)\n",
    "        \n",
    "        nn.init.zeros_(self.b_z)\n",
    "        nn.init.zeros_(self.b_r)\n",
    "        nn.init.zeros_(self.b_h)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        \"\"\"\n",
    "        Forward pass of a single GRU layer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, seq_len, input_size).\n",
    "            h (Tensor): Hidden state tensor of shape (batch_size, hidden_size).\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): Output sequence for this layer (batch_size, seq_len, hidden_size).\n",
    "            h (Tensor): Updated hidden state (batch_size, hidden_size).\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        output_sequence = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            # Compute update gate\n",
    "            z_t = torch.sigmoid(x_t @ self.W_xz + h @ self.W_hz + self.b_z)\n",
    "            \n",
    "            # Compute reset gate\n",
    "            r_t = torch.sigmoid(x_t @ self.W_xr + h @ self.W_hr + self.b_r)\n",
    "            \n",
    "            # Compute candidate hidden state\n",
    "            h_tilde = torch.tanh(x_t @ self.W_xh + (r_t * h) @ self.W_hh + self.b_h)\n",
    "\n",
    "            # Compute new hidden state\n",
    "            h = (1 - z_t) * h + z_t * h_tilde\n",
    "            \n",
    "            output_sequence.append(h.unsqueeze(1))  # Store output for each time step\n",
    "\n",
    "        # Concatenate outputs along time dimension\n",
    "        output = torch.cat(output_sequence, dim=1)\n",
    "        return output, h\n",
    "\n",
    "\n",
    "class MultiLayerGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, output_size, num_layers=1, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Wrapper around the GRU class\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_size (int): Number of hidden units per layer.\n",
    "            output_size (int): Number of output classes or regression targets.\n",
    "            num_layers (int): Number of stacked GRU layers.\n",
    "            dropout (float): Dropout probability applied between layers (default: 0.0, no dropout).\n",
    "        \"\"\"\n",
    "        super(MultiLayerGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Stack multiple GRU layers\n",
    "        self.gru_layers = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            # First layer takes input_size, subsequent layers take hidden_size\n",
    "            layer_input_size = input_size if layer == 0 else hidden_size\n",
    "            self.gru_layers.append(GRULayer(layer_input_size, hidden_size))\n",
    "\n",
    "        # Dropout layer applied between GRU layers (except for the last layer)\n",
    "        self.dropout_layer = nn.Dropout(dropout) if num_layers > 1 else nn.Identity()\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Initialize the output layer\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Applies Xavier uniform initialization to the final output layer.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        if self.fc.bias is not None:\n",
    "            nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the multi-layer GRU.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, seq_len, input_size).\n",
    "            h0 (Tensor, optional): Initial hidden state for all layers (shape: num_layers, batch_size, hidden_size).\n",
    "                                   If None, initializes to zeros.\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): Final output from the last layer (batch_size, output_size).\n",
    "            hidden_states (list of Tensors): Hidden states from all layers (num_layers, batch_size, hidden_size).\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        x = self.embedding(x)\n",
    "        # Initialize hidden states if not provided\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        hidden_states = []\n",
    "        h = h0\n",
    "\n",
    "        for layer in range(self.num_layers):\n",
    "            # Process input through each GRU layer\n",
    "            layer_output, h_layer = self.gru_layers[layer](x, h0[layer])\n",
    "            hidden_states.append(h_layer)\n",
    "            \n",
    "            # Apply dropout between layers (except last layer)\n",
    "            if layer < self.num_layers - 1:\n",
    "                x = self.dropout_layer(layer_output)\n",
    "            else:\n",
    "                x = layer_output\n",
    "        \n",
    "        # Use the last time step for classification\n",
    "        return self.fc(x[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0add6b21-7c9a-469c-8849-c0b55c973bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The Easy way\n",
    "class TorchGRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, num_layers, dropout,pad_idx):\n",
    "\n",
    "        super(TorchGRUModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size,padding_idx=pad_idx)\n",
    "        \n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(embedding_size, \n",
    "                         hidden_size, \n",
    "                         num_layers=num_layers, \n",
    "                         bidirectional=False, \n",
    "                         dropout=dropout if num_layers > 1 else 0,\n",
    "                         batch_first=True)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Linear layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Get embeddings\n",
    "        x = self.embedding(x)        \n",
    "        # GRU\n",
    "        gru_output, hidden = self.gru(x)\n",
    "        # Final hidden state\n",
    "        hidden = self.dropout(hidden[-1,:,:])\n",
    "        # Pass through linear layer\n",
    "        output_avg = gru_output.mean(dim=1)\n",
    "        return self.fc(output_avg)\n",
    "        # output shape: [batch_size, output_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dd69285-ae6c-413f-8d27-ed001773c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Epoch: 01, Train Loss: 0.4348, Train Acc: 84.48%, Val. Loss: 0.3103, Val. Acc: 89.62%\n",
      "1000\n",
      "Epoch: 02, Train Loss: 0.2444, Train Acc: 91.69%, Val. Loss: 0.2795, Val. Acc: 90.25%\n",
      "1000\n",
      "Epoch: 03, Train Loss: 0.1807, Train Acc: 93.91%, Val. Loss: 0.2726, Val. Acc: 91.28%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 21\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m evaluate(model, test_dl, criterion, device)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Val. Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val. Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, labels)\n\u001b[1;32m     17\u001b[0m acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(predictions, labels)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/ncem_env/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 64\n",
    "    MIN_FREQ = 5\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_DIM = 256\n",
    "    OUTPUT_DIM = 4\n",
    "    NUM_LAYERS = 2\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    train_dl, test_dl, vocabulary, num_classes = get_dataloaders(batch_size=BATCH_SIZE, min_freq=MIN_FREQ)\n",
    "    VOCAB_SIZE = len(vocabulary)\n",
    "    PAD_IDX = vocabulary['<pad>']\n",
    "    UNK_IDX = vocabulary['<unk>']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TorchGRUModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, 2, 0.5,PAD_IDX).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device)\n",
    "        valid_loss, valid_acc = evaluate(model, test_dl, criterion, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.4f}, Val. Acc: {valid_acc*100:.2f}%')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99a012ea-d9f7-4955-8f4d-35723821acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pure pytorch implementation of the LSTM layer for intuition\n",
    "class LSTMLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_size (int): Number of hidden units.\n",
    "        \"\"\"\n",
    "        super(LSTMLayer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # ----- Forget Gate -----\n",
    "        self.W_xf = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # ----- Input Gate -----\n",
    "        self.W_xi = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # ----- Candidate Cell State -----\n",
    "        self.W_xc = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hc = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # ----- Output Gate -----\n",
    "        self.W_xo = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_ho = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Uses Xavier & Orthogonal initialization for stability.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.W_xf)\n",
    "        nn.init.xavier_uniform_(self.W_xi)\n",
    "        nn.init.xavier_uniform_(self.W_xc)\n",
    "        nn.init.xavier_uniform_(self.W_xo)\n",
    "\n",
    "        nn.init.orthogonal_(self.W_hf)\n",
    "        nn.init.orthogonal_(self.W_hi)\n",
    "        nn.init.orthogonal_(self.W_hc)\n",
    "        nn.init.orthogonal_(self.W_ho)\n",
    "\n",
    "        nn.init.zeros_(self.b_f)\n",
    "        nn.init.zeros_(self.b_i)\n",
    "        nn.init.zeros_(self.b_c)\n",
    "        nn.init.zeros_(self.b_o)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of a single LSTM layer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, seq_len, input_size).\n",
    "            hidden (tuple): Tuple of hidden state (h) and cell state (c), both of shape (batch_size, hidden_size).\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): Output sequence for this layer (batch_size, seq_len, hidden_size).\n",
    "            (h, c) (Tensor, Tensor): Updated hidden and cell states (batch_size, hidden_size).\n",
    "        \"\"\"\n",
    "        h, c = hidden\n",
    "        batch_size, seq_len, input_size = x.size()\n",
    "        output_sequence = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            # Compute forget gate\n",
    "            f_t = torch.sigmoid(x_t @ self.W_xf + h @ self.W_hf + self.b_f)\n",
    "\n",
    "            # Compute input gate\n",
    "            i_t = torch.sigmoid(x_t @ self.W_xi + h @ self.W_hi + self.b_i)\n",
    "\n",
    "            # Compute candidate cell state\n",
    "            c_tilde = torch.tanh(x_t @ self.W_xc + h @ self.W_hc + self.b_c)\n",
    "\n",
    "            # Update cell state\n",
    "            c = f_t * c + i_t * c_tilde\n",
    "\n",
    "            # Compute output gate\n",
    "            o_t = torch.sigmoid(x_t @ self.W_xo + h @ self.W_ho + self.b_o)\n",
    "\n",
    "            # Compute new hidden state\n",
    "            h = o_t * torch.tanh(c)\n",
    "\n",
    "            output_sequence.append(h.unsqueeze(1))  # Store output for each time step\n",
    "\n",
    "        # Concatenate outputs along time dimension\n",
    "        output = torch.cat(output_sequence, dim=1)\n",
    "        return output, (h, c)\n",
    "\n",
    "class MultiLayerLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, num_layers=1, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Implements a multi-layer LSTM for AG News classification.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary.\n",
    "            embedding_size (int): Size of the word embeddings.\n",
    "            hidden_size (int): Number of hidden units per layer.\n",
    "            output_size (int): Number of output classes (4 for AG News).\n",
    "            num_layers (int): Number of stacked LSTM layers.\n",
    "            dropout (float): Dropout probability applied between layers.\n",
    "        \"\"\"\n",
    "        super(MultiLayerLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Stack multiple LSTM layers\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            layer_input_size = embedding_size if layer == 0 else hidden_size\n",
    "            self.lstm_layers.append(LSTMLayer(layer_input_size, hidden_size))\n",
    "\n",
    "        # Dropout layer applied between LSTM layers\n",
    "        self.dropout_layer = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Initialize the output layer\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Applies Xavier uniform initialization to the final output layer.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        if self.fc.bias is not None:\n",
    "            nn.init.zeros_(self.fc.bias)\n",
    "    \n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the multi-layer LSTM.\n",
    "    \n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, seq_len).\n",
    "            h0 (Tensor, optional): Initial hidden state.\n",
    "            c0 (Tensor, optional): Initial cell state.\n",
    "    \n",
    "        Returns:\n",
    "            output (Tensor): Final output from the last layer (batch_size, output_size).\n",
    "            hidden_states (list of (Tensor, Tensor)): Hidden and cell states from all layers [(h, c)].\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        \n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)  # (batch_size, seq_len, embedding_size)\n",
    "    \n",
    "        # Initialize hidden states if not provided\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n",
    "        if c0 is None:\n",
    "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n",
    "    \n",
    "        hidden_states = []\n",
    "        h, c = h0, c0\n",
    "    \n",
    "        # Process through each layer\n",
    "        for layer in range(self.num_layers):\n",
    "            # Process input through current LSTM layer\n",
    "            layer_output, (h_n, c_n) = self.lstm_layers[layer](x, (h[layer], c[layer]))\n",
    "            hidden_states.append((h_n, c_n))\n",
    "            \n",
    "            # Update hidden state for this layer\n",
    "            h = torch.cat([h[:layer], h_n.unsqueeze(0), h[layer+1:]]) if layer < self.num_layers - 1 else h_n.unsqueeze(0)\n",
    "            c = torch.cat([c[:layer], c_n.unsqueeze(0), c[layer+1:]]) if layer < self.num_layers - 1 else c_n.unsqueeze(0)\n",
    "            \n",
    "            # Set input for next layer (apply dropout except for last layer)\n",
    "            x = layer_output\n",
    "            if layer < self.num_layers - 1:\n",
    "                x = self.dropout_layer(x)\n",
    "    \n",
    "        # Use the final hidden state from the last layer for classification\n",
    "        final_hidden = h[-1]  # (batch_size, hidden_size)\n",
    "        \n",
    "        # Final classification layer\n",
    "        logits = self.fc(final_hidden)  # (batch_size, output_size)\n",
    "        \n",
    "        return logits, hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ef6d6eb-5541-4a9c-ae2d-162f42c76745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchMultiLayerLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, num_layers=1, dropout=0.0,pad_idx=0):\n",
    "        \"\"\"\n",
    "        Implements a multi-layer LSTM for AG News classification.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary.\n",
    "            embedding_size (int): Size of the word embeddings.\n",
    "            hidden_size (int): Number of hidden units per layer.\n",
    "            output_size (int): Number of output classes (4 for AG News).\n",
    "            num_layers (int): Number of stacked LSTM layers.\n",
    "            dropout (float): Dropout probability applied between layers.\n",
    "        \"\"\"\n",
    "        super(TorchMultiLayerLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size,padding_idx=pad_idx)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Use PyTorch's built-in LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Initialize the output layer\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Applies Xavier uniform initialization to the final output layer.\"\"\"\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        if self.fc.bias is not None:\n",
    "            nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the multi-layer LSTM.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, seq_len).\n",
    "            h0 (Tensor, optional): Initial hidden state.\n",
    "            c0 (Tensor, optional): Initial cell state.\n",
    "\n",
    "        Returns:\n",
    "            output (Tensor): Final output from the last layer (batch_size, output_size).\n",
    "            (h_n, c_n) (tuple): Final hidden and cell states.\n",
    "        \"\"\"\n",
    "        # Get batch size and sequence length\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Embed the input\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_size)\n",
    "\n",
    "        # Initialize hidden states if not provided\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n",
    "        if c0 is None:\n",
    "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        # Run through LSTM\n",
    "        lstm_output, (h_n, c_n) = self.lstm(embedded, (h0, c0))\n",
    "        \n",
    "        # Use the last hidden state for classification\n",
    "        final_hidden = h_n[-1]  # (batch_size, hidden_size)\n",
    "\n",
    "\n",
    "        output_avg = lstm_output.mean(dim=1)\n",
    "        return self.fc(output_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e888755-aa94-47c9-969e-ceeda0a0fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Epoch: 01, Train Loss: 0.4512, Train Acc: 84.24%, Val. Loss: 0.3370, Val. Acc: 88.91%\n",
      "1000\n",
      "Epoch: 02, Train Loss: 0.2596, Train Acc: 91.38%, Val. Loss: 0.2877, Val. Acc: 90.76%\n",
      "1000\n",
      "Epoch: 03, Train Loss: 0.1979, Train Acc: 93.38%, Val. Loss: 0.2664, Val. Acc: 91.18%\n",
      "1000\n",
      "Epoch: 04, Train Loss: 0.1525, Train Acc: 94.86%, Val. Loss: 0.2756, Val. Acc: 90.92%\n",
      "1000\n",
      "Epoch: 05, Train Loss: 0.1116, Train Acc: 96.26%, Val. Loss: 0.2856, Val. Acc: 90.97%\n",
      "1000\n",
      "Epoch: 06, Train Loss: 0.0803, Train Acc: 97.33%, Val. Loss: 0.3307, Val. Acc: 90.73%\n",
      "1000\n",
      "Epoch: 07, Train Loss: 0.0567, Train Acc: 98.05%, Val. Loss: 0.3550, Val. Acc: 91.15%\n",
      "1000\n",
      "Epoch: 08, Train Loss: 0.0437, Train Acc: 98.56%, Val. Loss: 0.3836, Val. Acc: 90.68%\n",
      "1000\n",
      "Epoch: 09, Train Loss: 0.0339, Train Acc: 98.87%, Val. Loss: 0.4403, Val. Acc: 90.87%\n",
      "1000\n",
      "Epoch: 10, Train Loss: 0.0271, Train Acc: 99.08%, Val. Loss: 0.4588, Val. Acc: 90.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 64\n",
    "    MIN_FREQ = 5\n",
    "    EMBEDDING_DIM = 128\n",
    "    HIDDEN_DIM = 256\n",
    "    OUTPUT_DIM = 4\n",
    "    NUM_LAYERS = 2\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    train_dl, test_dl, vocabulary, num_classes = get_dataloaders(batch_size=BATCH_SIZE, min_freq=MIN_FREQ)\n",
    "    VOCAB_SIZE = len(vocabulary)\n",
    "    PAD_IDX = vocabulary['<pad>']\n",
    "    UNK_IDX = vocabulary['<unk>']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TorchMultiLayerLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, 2, 0.5,PAD_IDX).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device)\n",
    "        valid_loss, valid_acc = evaluate(model, test_dl, criterion, device)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.4f}, Val. Acc: {valid_acc*100:.2f}%')\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d2aaa8f-9a62-467f-8eed-afcfaac8a6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and test losses over epochs. Notice the over-fitting.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, NUM_EPOCHS+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, NUM_EPOCHS+1), val_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0da2b-879d-4d7a-821c-afe16152490c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
