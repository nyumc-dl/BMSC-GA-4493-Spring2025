{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88732c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from xformers.ops import memory_efficient_attention  # Flash Attention\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f577efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f504b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset (Ensure the file is downloaded from Kaggle: https://www.kaggle.com/tboyle10/medicaltranscriptions)\n",
    "df = pd.read_csv(\"mtsamples.csv\")\n",
    "\n",
    "# Select relevant columns (assuming 'description' as text and 'medical_specialty' as labels)\n",
    "df = df[['transcription', 'medical_specialty']].dropna()\n",
    "\n",
    "# Reduce the number of categories for a binary classification task\n",
    "df['LABEL'] = df['medical_specialty'].apply(lambda x: 1 if x == ' Surgery' else 0)\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['transcription'].values, df['LABEL'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Define dataset parameters\n",
    "max_len = 512\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = MedicalDataset(train_texts, train_labels, tokenizer, max_len)\n",
    "val_dataset = MedicalDataset(val_texts, val_labels, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e70ce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    3878\n",
       "1    1088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8be168a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3972"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfd76f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c2e73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1055,  1011,  ...,     0,     0,     0],\n",
       "         [  101,  4241, 19386,  ...,     0,     0,     0],\n",
       "         [  101,  2381,  1997,  ...,  7175,  4030,   102],\n",
       "         ...,\n",
       "         [  101,  3653, 25918,  ..., 10814, 10440,   102],\n",
       "         [  101,  3653, 25918,  ...,  2059,  2741,   102],\n",
       "         [  101,  3114,  2005,  ...,  8995,  5751,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf48be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_max = 0\n",
    "for i in train_loader:\n",
    "    temp_max = i['input_ids'].max().detach().cpu().numpy()\n",
    "    if temp_max > curr_max:\n",
    "        curr_max = temp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4802891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_loader:\n",
    "    temp_max = i['input_ids'].max().detach().cpu().numpy()\n",
    "    if temp_max > curr_max:\n",
    "        curr_max = temp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1124fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = curr_max + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92e0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    # Cool thread to visualize it: https://datascience.stackexchange.com/questions/51065/what-is-the-positional-encoding-in-the-transformer-model\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model, device=device)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float, device=device).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, device=device).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model % 2 == 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:pe[:, 1::2].shape[1]])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  \n",
    "        self.register_buffer('pe', pe)\n",
    "    #Layer that adds the encoding.\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4eb9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlashAttentionLayer(nn.Module):\n",
    "    # Quick flash attention implementation\n",
    "    def __init__(self, embed_dim, nhead, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert embed_dim % nhead == 0, \"Embedding dimension must be divisible by number of heads\"\n",
    "        self.nhead = nhead\n",
    "        self.head_dim = embed_dim // nhead  # Get head dimensions\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn_proj_q = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_proj_k = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_proj_v = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, C = x.shape  # Batch, Sequence Length, Embedding Dim\n",
    "        # Project linearly for Q, K, V\n",
    "        q = self.attn_proj_q(x).view(B, L, self.nhead, self.head_dim).transpose(1, 2)  # (B, nh, L, head_dim)\n",
    "        k = self.attn_proj_k(x).view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        v = self.attn_proj_v(x).view(B, L, self.nhead, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Apply Flash Attention\n",
    "        attn_output = memory_efficient_attention(q, k, v)  # (B, nh, L, head_dim)\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2).reshape(B, L, C)  # Reshape back to (B, L, C)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0da585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Important to note the many parameters here, that's what we're optimizing\n",
    "class SmallFlashTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, nhead, num_layers, dropout, num_classes=2):\n",
    "        super().__init__()\n",
    "        #Make embedding and encoding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "        # Note: You can stack as many attention layers as you want\n",
    "        self.layers = nn.ModuleList([\n",
    "            FlashAttentionLayer(embed_dim, nhead, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        # Linear head\n",
    "        # Add extra layers for better feature extraction\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim * 2)\n",
    "        self.activation = nn.GELU()\n",
    "        self.fc2 = nn.Linear(embed_dim * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "        # Note how init weights is applied\n",
    "        self.apply(self._init_weights)\n",
    "    # Note the model initialization and weights\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "            \n",
    "            \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.float()\n",
    "        # Note the attention mask that is used to only pay attention \"backwards\" through the text.\n",
    "        #Not necessary for nucleic acids\n",
    "        if attention_mask is not None:\n",
    "            x = x * attention_mask.unsqueeze(-1)\n",
    "            # Mean pooling with mask - Note the representation used - Mean token representation here:\n",
    "            #x = x.sum(dim=1) / attention_mask.sum(dim=1, keepdim=True).clamp(min=1e-9)\n",
    "            # Last token representation version\n",
    "            x = x[:,-1,:] / attention_mask.sum(dim=1, keepdim=True).clamp(min=1e-9)\n",
    "        else:\n",
    "            #x = x.mean(dim=1)\n",
    "            x = x[:,-1,:]\n",
    "        # Note the Fully Connected head built on top of the attention layers\n",
    "        x = self.norm(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2cc97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You need to generate a training function, it's also good practice to do so.\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask)\n",
    "        # Debugging output shapes\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        scheduler.step()\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Debugging output shapes\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16d1a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-11 13:42:12,831] A new study created in memory with name: no-name-828eca21-7be0-49c4-9261-22bee44cacbb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.23138832997987926\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# For optuna, it's good to generate a function that runs all your suggestions through.\n",
    "def objective(trial):\n",
    "    #This is what we'll test, but it could be anything, HEHE!\n",
    "    embed_dim = trial.suggest_categorical(\"embed_dim\", [32, 64, 128])\n",
    "    nhead = trial.suggest_categorical(\"nhead\", [1, 2, 4])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [128,256,512])\n",
    "    # Make the transformer\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    model = SmallFlashTransformer(vocab_size, embed_dim, nhead, num_layers, dropout).to(device)\n",
    "    #NOTE this: Weighted classes for CrossEntropy loss\n",
    "    class_counts = df['LABEL'].value_counts().to_list()\n",
    "    weights = [1.0 / count for count in class_counts]\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    #Note the weight and label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "    #Note the difference between Adam and Adam Weight Decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    #Note difference between StepLR and OneCycleLR\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1) \n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=lr,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            pct_start=0.1\n",
    "        )\n",
    "    # Generate data loaders\n",
    "    # Set how many epocs you want\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, scheduler,criterion)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "        print(val_acc)\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss\n",
    "# Do you want to minimize or maximize the objective (val_loss?)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "# How many trials? optuna has several optimization algoirthms included\n",
    "study.optimize(objective, n_trials=20, timeout=600)\n",
    "#https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html Oh god, there's so many of them.\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Validation Loss:\", trial.value)\n",
    "print(\"  Best hyperparameters:\", trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b118e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
